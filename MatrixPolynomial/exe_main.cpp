#include <cstdio>
#include <cstdlib>
#include <string>
#include <exception>
#include <vector>
#include <map>
#include <set>
#include <algorithm>
#include <complex>
#include <functional>
#include <chrono>  // for high_resolution_clock
#include <iostream>

#define mexPrintf printf

//#define MKL_Complex8 std::complex<float>
#include <mkl.h>
#include "Matrix.h"
#include "Polynomial.h"


// http://www.cs.rochester.edu/~bh/cs400/using_lapack.html

/*
S	Real, the same as float in C
D	Double precision, the same as double in C
C	Complex
Z	Double complex
*/

/*
N		number of columns of A
nrhs	number of columns of b, usually 1
lda		number of rows (Leading Dimension of A) of A
ipiv	pivot indices
ldb		number of rows of b
*/



// CLAPACK http://icl.cs.utk.edu/lapack-for-windows/clapack/

extern double test_input_A[];
extern double test_input_B[];
extern double test_input_C[];

template<typename ElementType>
void test_matrix()
{
	Submatrix<double> tsA(test_input_A, 100, 100, 100);
	Submatrix<double> tsB(test_input_B, 100, 100, 100);
	Matrix<double> tsC1(test_input_C, 100, 100);
	Matrix<double> tsC2(test_input_C, 100, 100);
	Matrix<double> tsC3(test_input_C, 100, 100);

	auto t1 = std::chrono::high_resolution_clock::now();
	auto res1 = Submatrix<double>::trsylv(tsA, tsB, Submatrix<double>(tsC1));
	auto t2 = std::chrono::high_resolution_clock::now();
	auto res2 = Submatrix<double>::rtrsylv(tsA, tsB, Submatrix<double>(tsC2), 10);
	auto t3 = std::chrono::high_resolution_clock::now();
	// auto res3 = Submatrix<double>::recsy_trsylv(tsA, tsB, Submatrix<double>(tsC3));
	auto t4 = std::chrono::high_resolution_clock::now();

	auto tt1 = t2 - t1;
	auto tt2 = t3 - t2;
	auto tt3 = t4 - t3;

	ElementType simple_input[] = { { 1 },{ 2 },{ 3 },{ 4 },{ 5 },{ 6 },{ 7 },{ 8 },{ 9 },{ 1 },{ 2 },{ 3 },{ 4 },{ 5 },{ 6 },{ 7 },{ 8 },{ 9 },{ 1 },{ 2 },{ 3 },{ 4 },{ 5 },{ 6 },{ 7 } }; // [1,2,3 ; 4,5,6 ; 7,8,9]
	Matrix<ElementType> A(simple_input, 3, 3);
	Matrix<ElementType> B(simple_input, 2, 2);
	//A.add(B, 1);
	A.multiply(B, 2, 2, 2, MatrixIndex(1, 1), MatrixIndex(0, 0));
	Matrix<ElementType> C = Matrix<ElementType>::multiply(A, B, 2, 2, 2, MatrixIndex(1, 1), MatrixIndex(0, 0));
	int s = C.size();

	//Matrix<ElementType> temp(1, 3);
	//*temp.data() = { 1, 2 };
	//Matrix<ElementType> FiiTij1(1, 3);
	//*FiiTij1.data() = { 3, 4 };
	//{
	//	Matrix<ElementType> temp1 = Matrix<ElementType>::multiply(FiiTij1, temp, 1, 3, 1, { 0, 0 }, { 0, 0 });
	//	FiiTij1.assign(temp1, { 0, 0 });
	//}
	//FiiTij1.multiply(temp, 1, 3, 1, { 0, 0 }, { 0, 0 });


	Submatrix<ElementType> sA(&simple_input[1], 1, 1, 3);
	Submatrix<ElementType> sB(&simple_input[3], 1, 2, 3);

	sA.multiply(sB, 1, 2, 1, { 0, 0 }, { 0, 0 });

	std::vector<float> co = { 1, 5, 2, 7, 3.2, 9, -2 };
	Matrix<ElementType> D = sA.polynomial(co, { 0, 0 }, 2);
	s = D.size();
}

#include "SmartSwap.h"
void test_swap()
{
	//SmartSwap::Clusters clusters = { 0, 0, 1, 2, 0, 0, 1, 3, 3, 2, 1, 0 }; // AABCAABDDCBA
	//SmartSwap::Clusters order = { 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 3 };
	//SmartSwap::Clusters blocks = { 0, 1, 2, 3, 4, 4, 5, 6, 6, 7, 8, 9 };
	//SmartSwap::Clusters clusters = { 1, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 6, 7, 7, 8, 8, 2, 2, 9, 9 }; // ADDBBCCCCEEFGGHHDDII
	SmartSwap::ClustersWithBlocks test1_clusters = { { 1, 4, 2, 3, 3, 5, 6, 7, 8, 4, 9 } ,{ 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2 } }; // ADDBBCCCCEEFGGHHDDII
	SmartSwap::ClustersWithBlocks test1_order = { { 1, 2, 3, 3, 4, 4, 5, 6, 7, 8, 9 } ,{ 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2 } };
	SmartSwap swap(test1_clusters, test1_order, 9);
	auto locations = swap.Solve();
	for (auto& loc : locations)
	{
		std::cout << "Bad location " << loc.first << " -> " << loc.second << std::endl;
	}
}

int main(int argc, char* argv[])
{
	//test_matrix<double>();
	//return 0;
	//test_swap();
	//return;


	MKL_Complex8 simple_input[] = { { 1 },{ 2 },{ 3 },{ 4 },{ 5 },{ 6 },{ 7 },{ 8 },{ 9 },{ 1 },{ 2 },{ 3 },{ 4 },{ 5 },{ 6 },{ 7 },{ 8 },{ 9 },{ 1 },{ 2 },{ 3 },{ 4 },{ 5 },{ 6 },{ 7 } }; // [1,2,3 ; 4,5,6 ; 7,8,9]
	/*
	input =

	-2.9230    4.0088   -1.2366   -2.2269
	-1.5041    3.3731   -1.6432   -1.2215
	0.7115   -0.7935    0.5414    0.8421
	-1.1110    1.9330   -1.3704   -0.0316

	schur =
	1.0000    2.0000    3.0000    4.0000
	0    1.0100    2.0000    3.0000
	0         0   -2.0000   -3.0000
	0         0         0    0.9500
	*/
	//MKL_Complex8 input[] = { { -2.923 }, { 4.0088 }, { -1.2366 }, { -2.2269 }, { -1.5041 }, { 3.3731 }, { -1.6432 }, { -1.2215 }, { 0.7115 }, { -0.7935 }, { 0.5414 }, { 0.8421 }, { -1.111 }, { 1.9330 }, { -1.3704 }, { -0.0316 } };

	/*
	input =

	0.7706 + 0.7397i  -2.1563 - 0.4266i  -1.0131 + 3.2674i   3.1159 + 1.3099i
	0.7407 + 0.0297i  -0.1933 + 1.9755i   1.8440 + 0.7354i   0.0992 - 2.0023i
			-0.5988 - 0.1122i   1.1023 - 0.9572i  -0.4596 - 0.8178i  -0.2400 + 0.8342i
	0.6914 - 0.0182i  -0.9139 + 1.8199i   1.7558 + 0.4684i   0.8423 - 1.8974i

	schur =
	-2.0000 - 0.0000i   1.0438 - 0.9196i  -0.1536 - 2.6884i   5.1789 + 2.4558i
	0.0000 + 0.0000i   1.0006 - 0.0440i   1.2284 - 1.5646i   0.9208 + 1.8583i
	0.0000 + 0.0000i   0.0000 + 0.0000i   0.9298 + 0.0122i  -0.3916 + 0.7377i
	0.0000 + 0.0000i   0.0000 + 0.0000i   0.0000 + 0.0000i   1.0295 + 0.0318i

	delta = 0.09
	clusters = 1,2,3,2
	cluster order = 2,3,1
	*/
	MKL_Complex8 input[] = { { 0.7706, +0.7397 },{ -2.1563, -0.4266 },{ -1.0131, +3.2674 },{ 3.1159, +1.3099 },
	{ 0.7407, +0.0297 },{ -0.1933, +1.9755 },{ 1.8440, +0.7354 },{ 0.0992, -2.0023 },
	{ -0.5988, -0.1122 },{ 1.1023, -0.9572 },{ -0.4596, -0.8178 },{ -0.2400, +0.8342 },
	{ 0.6914, -0.0182 },{ -0.9139, +1.8199 },{ 1.7558, +0.4684 },{ 0.8423, -1.8974 } };

	MKL_Complex8 big_input[] = {
	{ 0.814723686393179, 0 },{ 0.655740699156587, 0 },{ 0.438744359656398, 0 },{ 0.751267059305653, 0 },{ 0.351659507062997, 0 },{ 0.162182308193243, 0 },{ 0.106652770180584, 0 },{ 0.853031117721894, 0 },{ 0.780252068321138, 0 },{ 0.547008892286345, 0 },{ 0.644318130193692, 0 },{ 0.311102286650413, 0 },{ 0.0855157970900440, 0 },{ 0.0377388662395521, 0 },{ 0.0305409463046367, 0 },{ 0.0596188675796392, 0 },{ 0.173388613119006, 0 },{ 0.951630464777727, 0 },{ 0.0326008205305280, 0 },{ 0.251806122472313, 0 },
	{ 0.905791937075619, 0 },{ 0.0357116785741896, 0 },{ 0.381558457093008, 0 },{ 0.255095115459269, 0 },{ 0.830828627896291, 0 },{ 0.794284540683907, 0 },{ 0.961898080855054, 0 },{ 0.622055131485066, 0 },{ 0.389738836961253, 0 },{ 0.296320805607773, 0 },{ 0.378609382660268, 0 },{ 0.923379642103244, 0 },{ 0.262482234698333, 0 },{ 0.885168008202475, 0 },{ 0.744074260367462, 0 },{ 0.681971904149063, 0 },{ 0.390937802323736, 0 },{ 0.920332039836564, 0 },{ 0.561199792709660, 0 },{ 0.290440664276979, 0 },
	{ 0.126986816293506, 0 },{ 0.849129305868777, 0 },{ 0.765516788149002, 0 },{ 0.505957051665142, 0 },{ 0.585264091152724, 0 },{ 0.311215042044805, 0 },{ 0.00463422413406744, 0 },{ 0.350952380892271, 0 },{ 0.241691285913833, 0 },{ 0.744692807074156, 0 },{ 0.811580458282477, 0 },{ 0.430207391329584, 0 },{ 0.801014622769739, 0 },{ 0.913286827639239, 0 },{ 0.500022435590201, 0 },{ 0.0424311375007417, 0 },{ 0.831379742839070, 0 },{ 0.0526769976807926, 0 },{ 0.881866500451810, 0 },{ 0.617090884393223, 0 },
	{ 0.913375856139019, 0 },{ 0.933993247757551, 0 },{ 0.795199901137063, 0 },{ 0.699076722656686, 0 },{ 0.549723608291140, 0 },{ 0.528533135506213, 0 },{ 0.774910464711502, 0 },{ 0.513249539867053, 0 },{ 0.403912145588115, 0 },{ 0.188955015032545, 0 },{ 0.532825588799455, 0 },{ 0.184816320124136, 0 },{ 0.0292202775621463, 0 },{ 0.796183873585212, 0 },{ 0.479922141146060, 0 },{ 0.0714454646006424, 0 },{ 0.803364391602440, 0 },{ 0.737858095516997, 0 },{ 0.669175304534394, 0 },{ 0.265280909810029, 0 },
	{ 0.632359246225410, 0 },{ 0.678735154857774, 0 },{ 0.186872604554379, 0 },{ 0.890903252535799, 0 },{ 0.917193663829810, 0 },{ 0.165648729499781, 0 },{ 0.817303220653433, 0 },{ 0.401808033751942, 0 },{ 0.0964545251683886, 0 },{ 0.686775433365315, 0 },{ 0.350727103576883, 0 },{ 0.904880968679893, 0 },{ 0.928854139478045, 0 },{ 0.0987122786555743, 0 },{ 0.904722238067363, 0 },{ 0.521649842464284, 0 },{ 0.0604711791698936, 0 },{ 0.269119426398556, 0 },{ 0.190433267179954, 0 },{ 0.824376266688835, 0 },
	{ 0.0975404049994095, 0 },{ 0.757740130578333, 0 },{ 0.489764395788231, 0 },{ 0.959291425205444, 0 },{ 0.285839018820374, 0 },{ 0.601981941401637, 0 },{ 0.868694705363510, 0 },{ 0.0759666916908419, 0 },{ 0.131973292606335, 0 },{ 0.183511155737270, 0 },{ 0.939001561999887, 0 },{ 0.979748378356085, 0 },{ 0.730330862855453, 0 },{ 0.261871183870716, 0 },{ 0.609866648422558, 0 },{ 0.0967300257808670, 0 },{ 0.399257770613576, 0 },{ 0.422835615008808, 0 },{ 0.368916546063895, 0 },{ 0.982663399721950, 0 },
	{ 0.278498218867048, 0 },{ 0.743132468124916, 0 },{ 0.445586200710900, 0 },{ 0.547215529963803, 0 },{ 0.757200229110721, 0 },{ 0.262971284540144, 0 },{ 0.0844358455109103, 0 },{ 0.239916153553658, 0 },{ 0.942050590775485, 0 },{ 0.368484596490337, 0 },{ 0.875942811492984, 0 },{ 0.438869973126103, 0 },{ 0.488608973803579, 0 },{ 0.335356839962797, 0 },{ 0.617666389588455, 0 },{ 0.818148553859625, 0 },{ 0.526875830508296, 0 },{ 0.547870901214845, 0 },{ 0.460725937260412, 0 },{ 0.730248792267598, 0 },
	{ 0.546881519204984, 0 },{ 0.392227019534168, 0 },{ 0.646313010111265, 0 },{ 0.138624442828679, 0 },{ 0.753729094278495, 0 },{ 0.654079098476782, 0 },{ 0.399782649098897, 0 },{ 0.123318934835166, 0 },{ 0.956134540229802, 0 },{ 0.625618560729690, 0 },{ 0.550156342898422, 0 },{ 0.111119223440599, 0 },{ 0.578525061023439, 0 },{ 0.679727951377338, 0 },{ 0.859442305646212, 0 },{ 0.817547092079286, 0 },{ 0.416799467930787, 0 },{ 0.942736984276934, 0 },{ 0.981637950970750, 0 },{ 0.343877004114983, 0 },
	{ 0.957506835434298, 0 },{ 0.655477890177557, 0 },{ 0.709364830858073, 0 },{ 0.149294005559057, 0 },{ 0.380445846975357, 0 },{ 0.689214503140008, 0 },{ 0.259870402850654, 0 },{ 0.183907788282417, 0 },{ 0.575208595078466, 0 },{ 0.780227435151377, 0 },{ 0.622475086001228, 0 },{ 0.258064695912067, 0 },{ 0.237283579771521, 0 },{ 0.136553137355370, 0 },{ 0.805489424529686, 0 },{ 0.722439592366842, 0 },{ 0.656859890973707, 0 },{ 0.417744104316662, 0 },{ 0.156404952226563, 0 },{ 0.584069333278452, 0 },
	{ 0.964888535199277, 0 },{ 0.171186687811562, 0 },{ 0.754686681982361, 0 },{ 0.257508254123736, 0 },{ 0.567821640725221, 0 },{ 0.748151592823710, 0 },{ 0.800068480224308, 0 },{ 0.239952525664903, 0 },{ 0.0597795429471558, 0 },{ 0.0811257688657853, 0 },{ 0.587044704531417, 0 },{ 0.408719846112552, 0 },{ 0.458848828179931, 0 },{ 0.721227498581740, 0 },{ 0.576721515614685, 0 },{ 0.149865442477967, 0 },{ 0.627973359190104, 0 },{ 0.983052466469856, 0 },{ 0.855522805845911, 0 },{ 0.107769015243743, 0 },
	{ 0.157613081677548, 0 },{ 0.706046088019609, 0 },{ 0.276025076998578, 0 },{ 0.840717255983663, 0 },{ 0.0758542895630636, 0 },{ 0.450541598502498, 0 },{ 0.431413827463545, 0 },{ 0.417267069084370, 0 },{ 0.234779913372406, 0 },{ 0.929385970968730, 0 },{ 0.207742292733028, 0 },{ 0.594896074008614, 0 },{ 0.963088539286913, 0 },{ 0.106761861607241, 0 },{ 0.182922469414914, 0 },{ 0.659605252908307, 0 },{ 0.291984079961715, 0 },{ 0.301454948712065, 0 },{ 0.644764536870088, 0 },{ 0.906308150649733, 0 },
	{ 0.970592781760616, 0 },{ 0.0318328463774207, 0 },{ 0.679702676853675, 0 },{ 0.254282178971531, 0 },{ 0.0539501186666072, 0 },{ 0.0838213779969326, 0 },{ 0.910647594429523, 0 },{ 0.0496544303257421, 0 },{ 0.353158571222071, 0 },{ 0.775712678608402, 0 },{ 0.301246330279491, 0 },{ 0.262211747780845, 0 },{ 0.546805718738968, 0 },{ 0.653757348668560, 0 },{ 0.239932010568717, 0 },{ 0.518594942510538, 0 },{ 0.431651170248720, 0 },{ 0.701098755900926, 0 },{ 0.376272210278832, 0 },{ 0.879653724481905, 0 },
	{ 0.957166948242946, 0 },{ 0.276922984960890, 0 },{ 0.655098003973841, 0 },{ 0.814284826068816, 0 },{ 0.530797553008973, 0 },{ 0.228976968716819, 0 },{ 0.181847028302853, 0 },{ 0.902716109915281, 0 },{ 0.821194040197959, 0 },{ 0.486791632403172, 0 },{ 0.470923348517591, 0 },{ 0.602843089382083, 0 },{ 0.521135830804002, 0 },{ 0.494173936639270, 0 },{ 0.886511933076101, 0 },{ 0.972974554763863, 0 },{ 0.0154871256360190, 0 },{ 0.666338851584426, 0 },{ 0.190923695236303, 0 },{ 0.817760559370642, 0 },
	{ 0.485375648722841, 0 },{ 0.0461713906311539, 0 },{ 0.162611735194631, 0 },{ 0.243524968724989, 0 },{ 0.779167230102011, 0 },{ 0.913337361501670, 0 },{ 0.263802916521990, 0 },{ 0.944787189721646, 0 },{ 0.0154034376515551, 0 },{ 0.435858588580919, 0 },{ 0.230488160211559, 0 },{ 0.711215780433683, 0 },{ 0.231594386708524, 0 },{ 0.779051723231275, 0 },{ 0.0286741524641061, 0 },{ 0.648991492712356, 0 },{ 0.984063724379154, 0 },{ 0.539126465042857, 0 },{ 0.428252992979386, 0 },{ 0.260727999055465, 0 },
	{ 0.800280468888800, 0 },{ 0.0971317812358475, 0 },{ 0.118997681558377, 0 },{ 0.929263623187228, 0 },{ 0.934010684229183, 0 },{ 0.152378018969223, 0 },{ 0.145538980384717, 0 },{ 0.490864092468080, 0 },{ 0.0430238016578078, 0 },{ 0.446783749429806, 0 },{ 0.844308792695389, 0 },{ 0.221746734017240, 0 },{ 0.488897743920167, 0 },{ 0.715037078400694, 0 },{ 0.489901388512224, 0 },{ 0.800330575352402, 0 },{ 0.167168409914656, 0 },{ 0.698105520180308, 0 },{ 0.482022061031856, 0 },{ 0.594356250664331, 0 },
	{ 0.141886338627215, 0 },{ 0.823457828327293, 0 },{ 0.498364051982143, 0 },{ 0.349983765984809, 0 },{ 0.129906208473730, 0 },{ 0.825816977489547, 0 },{ 0.136068558708664, 0 },{ 0.489252638400019, 0 },{ 0.168990029462704, 0 },{ 0.306349472016557, 0 },{ 0.194764289567049, 0 },{ 0.117417650855806, 0 },{ 0.624060088173690, 0 },{ 0.903720560556316, 0 },{ 0.167927145682257, 0 },{ 0.453797708726920, 0 },{ 0.106216344928664, 0 },{ 0.666527913402587, 0 },{ 0.120611613297162, 0 },{ 0.0225125927402318, 0 },
	{ 0.421761282626275, 0 },{ 0.694828622975817, 0 },{ 0.959743958516081, 0 },{ 0.196595250431208, 0 },{ 0.568823660872193, 0 },{ 0.538342435260057, 0 },{ 0.869292207640089, 0 },{ 0.337719409821377, 0 },{ 0.649115474956452, 0 },{ 0.508508655381127, 0 },{ 0.225921780972399, 0 },{ 0.296675873218327, 0 },{ 0.679135540865748, 0 },{ 0.890922504330789, 0 },{ 0.978680649641159, 0 },{ 0.432391503783462, 0 },{ 0.372409740055537, 0 },{ 0.178132454400338, 0 },{ 0.589507484695059, 0 },{ 0.425259320214135, 0 },
	{ 0.915735525189067, 0 },{ 0.317099480060861, 0 },{ 0.340385726666133, 0 },{ 0.251083857976031, 0 },{ 0.469390641058206, 0 },{ 0.996134716626886, 0 },{ 0.579704587365570, 0 },{ 0.900053846417662, 0 },{ 0.731722385658670, 0 },{ 0.510771564172110, 0 },{ 0.170708047147859, 0 },{ 0.318778301925882, 0 },{ 0.395515215668593, 0 },{ 0.334163052737496, 0 },{ 0.712694471678914, 0 },{ 0.825313795402046, 0 },{ 0.198118402542975, 0 },{ 0.128014399720173, 0 },{ 0.226187679752676, 0 },{ 0.312718886820616, 0 },
	{ 0.792207329559554, 0 },{ 0.950222048838355, 0 },{ 0.585267750979777, 0 },{ 0.616044676146639, 0 },{ 0.0119020695012414, 0 },{ 0.0781755287531837, 0 },{ 0.549860201836332, 0 },{ 0.369246781120215, 0 },{ 0.647745963136307, 0 },{ 0.817627708322262, 0 },{ 0.227664297816554, 0 },{ 0.424166759713807, 0 },{ 0.367436648544477, 0 },{ 0.698745832334795, 0 },{ 0.500471624154843, 0 },{ 0.0834698148589140, 0 },{ 0.489687638016024, 0 },{ 0.999080394761361, 0 },{ 0.384619124369411, 0 },{ 0.161484744311750, 0 },
	{ 0.959492426392903, 0 },{ 0.0344460805029088, 0 },{ 0.223811939491137, 0 },{ 0.473288848902729, 0 },{ 0.337122644398882, 0 },{ 0.442678269775446, 0 },{ 0.144954798223727, 0 },{ 0.111202755293787, 0 },{ 0.450923706430945, 0 },{ 0.794831416883453, 0 },{ 0.435698684103899, 0 },{ 0.507858284661118, 0 },{ 0.987982003161633, 0 },{ 0.197809826685929, 0 },{ 0.471088374541939, 0 },{ 0.133171007607162, 0 },{ 0.339493413390758, 0 },{ 0.171121066356432, 0 },{ 0.582986382747674, 0 },{ 0.178766186752368, 0 } };

	/*
		[0.422885689100085, 0.699887849928292, 0.530864280694127, 0.968649330231094, 0.778802241824093,
		0.0942293388877347, 0.638530758271838, 0.654445707757066, 0.531333906565675, 0.423452918962738,
		0.598523668756741, 0.0336038360664295, 0.407619197041153, 0.325145681820560, 0.0908232857874395,
		0.470924256358334, 0.0688060991180512, 0.819981222781941, 0.105629203329022, 0.266471490779072,
		0.695949313301608, 0.319599735180496, 0.718358943205884, 0.610958658746201, 0.153656717591307]
	 */
	MKL_Complex8 small_input[] = {
		{ 0.422885689100085, 0 },{ 0.699887849928292, 0 },{ 0.530864280694127, 0 },{ 0.968649330231094, 0 },{ 0.778802241824093, 0 },
		{ 0.0942293388877347, 0 },{ 0.638530758271838, 0 },{ 0.654445707757066, 0 },{ 0.531333906565675, 0 },{ 0.423452918962738, 0 },
		{ 0.598523668756741, 0 },{ 0.0336038360664295, 0 },{ 0.407619197041153, 0 },{ 0.325145681820560, 0 },{ 0.0908232857874395, 0 },
		{ 0.470924256358334, 0 },{ 0.0688060991180512, 0 },{ 0.819981222781941, 0 },{ 0.105629203329022, 0 },{ 0.266471490779072, 0 },
		{ 0.695949313301608, 0 },{ 0.319599735180496, 0 },{ 0.718358943205884, 0 },{ 0.610958658746201, 0 },{ 0.153656717591307 , 0 }
	};

	int n = 5;
	// X^5-3*X^3+9*X^2-X
	std::vector<float> co = { 0, -1, 9, -3, 0, 1 };
	//Matrix<MKL_Complex8> input_matrix(simple_input, 4, 4);// (big_input, 20, 20);
	double big_input_f[20 * 20];
	CONVERT_REAL(double, big_input_f, big_input, 20 * 20);
#define ElmType double //MKL_Complex8
#define InputData big_input_f //big_input
#define InputDataDim 20
	Matrix<ElmType> input_matrix(InputData, InputDataDim, InputDataDim);
	Polynomial<ElmType> p(input_matrix);
	Matrix<ElmType> poly = p.calculatePolynomial(co, 0.1, SchurDecompositionAlgorithm::Default, EigenvaluesClusterSortAlgorithm::SmartSwapSort, ParlettRecurrence, SylvesterRecsy);

	std::vector<Benchmark::CheckpointType> checkpoints = {
		Benchmark::CheckpointType::SchurDecomposition,
		//Benchmark::CheckpointType::EigenvaluesInit,
		Benchmark::CheckpointType::EigenvaluesCluster,
		Benchmark::CheckpointType::EigenvaluesPermute,
		Benchmark::CheckpointType::EigenvaluesSort,
		Benchmark::CheckpointType::PolynomialCalculation,
		Benchmark::CheckpointType::BlockParlettRecurrence,
		Benchmark::CheckpointType::SylvesterSolve,
		Benchmark::CheckpointType::FinalMultiplication,
	};
	for (auto cp : checkpoints)
	{
		auto time = Benchmark::Instance().Get(cp);
		std::cout << "Checkpoint " << cp << ": " << time.count() << std::endl;
	}
	return 0;
}

// Way 1: Layers + small SYL equations. Paralleled by layers
// Way 2: From left to right. Fewer SYLs. Parallelism ??

/*
benchmarking:
Automate the benchmarking for easy execution/reexecution. Generate graphs in matlab based on the exported results
1. Each scaling experiment has to have X - size of matrix (up to 8K*8K), Y - time (logarithmic scale or divided by n^3)
- sequential sizes - 1 to 8K, with 24 cores
- Show X datasets on each graph (all different ways to calculate and the naive)
- Compare with baseline of a known 3rd party algo - recsy / schur decomp.
	- OR breakdown the execution time to the different components - schur, my code, sylvester - and show the percentage of the CPU time in the polynomial calculation
2. Scaling #2 - X axis is #cores, on fixes matrix size

3 different parameters in benchmark:
- size of clusters on the diagonal (clusters with 50 values, clusters with 1K values)
- The variance of the cluster sizes (all are the same size, different sizes) (half 50-size blocks, half 1K-size blocks)
- The rank of the polynomial (rank 4, rank n-1, rank 1K)

Input generation:
Generate clustered matrix manually in matlab
generate random matrix which will contain the "eigenvectors"
L = diag(1,20)
V = randn(20,20)
A = V\(L*V)
spy(schur(A))
- make sure during the algo execution that the clusters are as expected.
 */

/* TODO:
0. Convert to real values - done.
1. Implement way#2 in addition to BlockParlettRecurrence (way#1)
2. Parallel
- matrix multiply (split to several concurrent LAPACK calls)
- Patterson-Stockmeyer (Van Loan - PS-MV)
- way#1 - BlockParlettRecurrence by layers
- way#2 - ??
3. Benchmarking - way#1 vs way#2 vs P-way#1 vs P-way#2

way#1 - parallel in layers + parallel matrix multiplication + recsy non-parallel
way#2 - parallel recsy, sequential blocks









histograms + graphs

1. 1-1 blocks - eigenvalues very different. schur-parlett on the whole matrix. Work of n^3.
2. clusters of 100-100 out of 8000-8000 matrix with high rank (1000). SYL on bigger chunks.
	Try to prove that higham-davis algo from sec. 9 gives a boost to the performance, where schur-parlett can't be run on (very similar eigenvalues, high error rate)
3. Few clusters (naive polynomial calculation)

Things we want to prove:
1. small blocks give perf. boost over the naive approach (A^300 will be calculated in sqrt(d) steps, not so naive)
2. diff between way#1 and way#2.


*/
